# Use of AI Tools

To augment my manual testing efforts and ensure comprehensive coverage of input validation and edge cases, we utilized an AI-powered large language model. The AI tool was used in this domain testing process is **Gemini 2.5 Pro Preview**.

## Prompts Used
The process involved a series of iterative prompts to generate a baseline of test cases, which were then refined.

1.  **Initial Broad Prompt:**
    - "Generate a list of test cases for a 'User Profile Update' page. The page has two main sections: 'Update Profile' with fields for First Name, Last Name, Email, Phone, Address, Postcode, City, and Country; and a 'Change Password' section with fields for Current Password, New Password, and Confirm New Password. Use equivalence partitioning and boundary value analysis."

2.  **Refinement Prompt for Profile Details:**
    - "Refine the test cases for the 'Update Profile' section. Assume the following constraints:
      - First Name/Last Name: Alphabetic, min length 2, max length 50.
      - Email: Must be a valid format.
      - Phone: Optional, should ideally be numeric.
      - Postcode: For Austria, it's a 4-digit number.
      - City: Alphabetic.
      - Country: Must be a valid country from a predefined list.
    Generate positive and negative test cases for each field."

3.  **Refinement Prompt for Password Complexity:**
    - "Now, create detailed test cases for the 'Change Password' feature. The password policy is:
      - Must be at least 8 characters long.
      - Must contain at least one uppercase letter, one lowercase letter, one number, and one special symbol (e.g., @, !, #).
      - The new password cannot be the same as the old password.
      - The 'New Password' and 'Confirm New Password' fields must match.
    Cover each rule individually as a failure case, plus a happy path success case and cases for empty fields."

## How AI-Generated Results were Validated and Refined
  - The raw output from ChatGPT served as a starting point. The following validation and refinement steps were performed manually:
      - **Contextualization:** The AI's suggestions were generic (e.g., "Enter invalid postcode"). We refined these to match our specific business logic, such as `Postcode: 101` (too short for Austria) and `Postcode: A101` (invalid characters for Austria).
      - **Elimination of Redundancy:** The AI produced several similar test cases (e.g., testing invalid special characters in 'First Name' with `!`, then `#`, then `*`). These were consolidated into a single representative test case (e.g., `TC105`: Verify First Name with numeric characters) to improve efficiency.
      - **Addition of Integration and Workflow Tests:** The AI is proficient at generating tests for individual fields but less so for integrated, multi-step user workflows. We manually designed test cases that verify the interaction between fields (`TC125`), the overall form submission (`TC124`), and UI-specific functionality (`TC140`, `TC141`).
      - **Alignment with Application-Specific Behavior:** Initial exploratory testing revealed specific bugs, like the `First Name` and `Last Name` fields being swapped (`TC101`). This real-world finding, which the AI could not have predicted, was added as a manual test case. Similarly, the specific error message "Resource not found" was added to the `Actual Result` column based on manual execution.

## Attribution of Test Cases
  - **AI-Generated (and subsequently refined):**
      - `TC102-TC123`: These cases, which systematically test the boundaries, valid inputs, and invalid partitions for each profile field, were initially generated by the AI.
      - `TC127-TC139`: The comprehensive set of tests covering every password complexity rule (length, character types, matching, etc.) originated from the AI prompts.
  - **Manually-Created:**
      - `TC101`: This test case was created after observing a specific bug during exploratory testing (swapped fields).
      - `TC124-TC126`: These are holistic form-level tests designed to check overall functionality, which requires a human understanding of the system as a whole.
      - `TC140-TC141`: These UI interaction tests for the "Show/Hide Password" toggle were created manually as they test a specific frontend component's behavior.
      - `TC201-TC211`: The entire "Order Management" feature set was tested manually. These test cases require deep contextual knowledge of the business workflow, data persistence across pages, and user journey simulation, which is beyond the scope of simple AI generation.

## Justification for Final Selections

The guiding principle for the merger was to leverage each source for its strengths. The AI-generated tests provided a rigorous and systematic foundation for input validation, while manual tests focused on user flows, integration points, and application-specific logic.

### Feature 01: Update My Profile
  - **Profile Fields (`TC101-TC126`):**
      - **AI-Generated Kept:** The BVA and EP tests for `First Name`, `Email`, `Postcode`, etc. (`TC102-TC123`) were kept as they provide excellent, methodical coverage of field-level validation rules that is time-consuming to design manually.
      - **Manual Kept:** `TC101` was essential as it targets a specific, high-priority bug found during exploratory testing. `TC124-TC126` were kept because they test the form as a single unit, verifying that valid data persists, invalid data prevents submission, and no-change submissions are handled gracefullyâ€”scenarios the AI did not consider.
      - **Duplicates Removed:** The AI initially produced separate tests for different types of invalid characters in name fields (e.g., `John!`, `John*`, `John%`). These were consolidated into one representative test for "invalid characters" to streamline testing. The final list uses `TC105` (numeric characters) as the primary example of this category.
  - **Password Change (`TC127-TC141`):**
      - **AI-Generated Kept:** The tests for each password policy rule (`TC127-TC139`) were almost entirely adopted from the AI output. The AI's ability to systematically generate a test for each permutation of the complexity rules was highly effective.
      - **Manual Kept:** The UI functionality tests for the "Show/Hide Password" toggles (`TC140`, `TC141`) were added manually, as this is an interactive element not covered by the data-focused AI prompts.
      - **Duplicates Removed:** An AI-generated test for a password exceeding a maximum length was removed, as the system requirements did not specify a maximum length, making the test out of scope.

### Feature 02: Order Management
  - **All Manual (`TC201-TC211`):** This entire suite was manually designed. The justification is that these tests are heavily dependent on business context and state management. For example, `TC202` (search matching multiple records), `TC206` (navigating from list to detail), and `TC208` (verifying data persistence after navigation) require an understanding of the end-to-end user journey and data flow that is best captured through human-led test design. The AI is not equipped to generate meaningful tests for such stateful, multi-step workflows.
